version: '3.7'
services:
  # maintenance
  watchtower:
    image: containrrr/watchtower:latest
    container_name: watchtower
    restart: always
    environment:
      TZ: '{{ timezone }}'
      DOCKER_HOST: tcp://docker-proxy:2375
      WATCHTOWER_SCHEDULE: '{{ watchtower_schedule | default("0 0 0 * * *") }}'
      WATCHTOWER_NOTIFICATIONS: shoutrrr
      WATCHTOWER_NOTIFICATIONS_LEVEL: '{{ watchtower_slack_level }}'
      WATCHTOWER_NOTIFICATION_URL: '{{ watchtower_slack_url }}'
      WATCHTOWER_NOTIFICATION_TEMPLATE: '{{ watchtower_slack_template }}'
      WATCHTOWER_HTTP_API_TOKEN: '{{ watchtower_http_api_token }}'
      WATCHTOWER_HTTP_API_METRICS: '{{ watchtower_http_api_metrics | default(true) }}'
      WATCHTOWER_CLEANUP: '{{ watchtower_cleanup | default(true) }}'
      WATCHTOWER_DEBUG: '{{ watchtower_debug | default(false) }}'
    expose:
      - 8080
    networks:
      - monitoring
      - docker
  dozzle:
    image: amir20/dozzle:latest
    container_name: dozzle
    restart: always
    expose:
      - 8080
    environment:
      DOCKER_HOST: tcp://docker-proxy:2375
    networks:
      - proxy
      - docker
    labels:
      - traefik.enable=true
      - traefik.http.routers.dozzle.rule=Host(`dozzle.{{ domain }}`)
      - traefik.http.routers.dozzle.entrypoints=https
      - traefik.http.routers.dozzle.tls=true
      - traefik.http.routers.dozzle.tls.certresolver=digitalocean
      - traefik.http.routers.dozzle.middlewares=auth@file,rate-limit@file
  portainer:
    image: portainer/portainer-ce:latest
    container_name: portainer
    restart: unless-stopped
    command: --host tcp://docker-proxy:2375
    expose:
      - 9000
    volumes:
      - portainer:/data
    networks:
      - proxy
      - docker
    labels:
      - traefik.enable=true
      - traefik.http.routers.portainer.rule=Host(`portainer.{{ domain }}`)
      - traefik.http.routers.portainer.entrypoints=https
      - traefik.http.routers.portainer.tls=true
      - traefik.http.routers.portainer.tls.certresolver=digitalocean
      - traefik.http.routers.portainer.middlewares=auth@file,rate-limit@file
      - traefik.http.services.portainer-network.loadbalancer.server.port=9000

  # security
  docker-proxy:
    image: tecnativa/docker-socket-proxy:latest
    container_name: docker-proxy
    restart: always
    expose:
      - 2375
    environment:
      INFO: 1
      CONTAINERS: 1
      IMAGES: 1
      NETWORKS: 1
      VOLUMES: 1
      SERVICES: 1
      POST: 1
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - docker
  fail2ban:
    image: crazymax/fail2ban:latest
    container_name: fail2ban
    restart: always
    network_mode: host
    environment:
      TZ: '{{ timezone }}'
      F2B_LOG_TARGET: STDOUT
      F2B_LOG_LEVEL: INFO
      F2B_DB_PURGE_AGE: 1d
      SSMTP_HOST: '{{ mail.host }}'
      SSMTP_PORT: '{{ mail.port }}'
      # SSMTP_HOSTNAME: example.com
      SSMTP_USER: '{{ mail.accounts.auth.email }}'
      SSMTP_PASSWORD: '{{ mail.accounts.auth.password }}'
      SSMTP_TLS: 'YES'
    volumes:
      - /var/log:/var/log:ro
      - '{{ root_path }}/fail2ban:/data'
    cap_add:
      - NET_ADMIN
      - NET_RAW

  # proxy
  traefik:
    image: traefik:latest
    container_name: traefik
    restart: unless-stopped
    healthcheck:
      test: traefik healthcheck
      interval: 30s
      timeout: 3s
      retries: 30
    ports:
      - '80:80'
      - '443:443'
    expose:
      - 9000
    environment:
      TZ: '{{ timezone }}'
      DO_AUTH_TOKEN: '{{ digital_ocean_token }}'
    volumes:
      - /var/log/traefik:/var/log
      - '{{ root_path }}/traefik.yml:/etc/traefik/traefik.yml'
      - '{{ root_path }}/traefik:/etc/traefik'
    networks:
      proxy:
        ipv4_address: 172.20.1.2
      docker: {}
    extra_hosts:
      - 'dockerhost:172.20.1.1'
    labels:
      - traefik.enable=true
      - traefik.http.routers.api.rule=Host(`traefik.{{ domain }}`)
      - traefik.http.routers.api.entrypoints=https
      - traefik.http.routers.api.service=api@internal
      - traefik.http.routers.api.tls=true
      - traefik.http.routers.api.tls.certresolver=digitalocean
      - traefik.http.routers.api.middlewares=auth@file,rate-limit@file
  authelia:
    image: authelia/authelia
    container_name: authelia
    restart: unless-stopped
    healthcheck:
      test: wget --no-verbose --tries=1 --spider http://localhost:9091 || exit 1
      interval: 30s
      timeout: 3s
      retries: 30
    expose:
      - 9091
    environment:
      TZ: '{{ timezone }}'
      PUID: 1000
      PGID: 1000
    volumes:
      - /var/log/authelia:/var/log
      - '{{ root_path }}/authelia:/config'
    networks:
      - proxy
    labels:
      - traefik.enable=true
      - traefik.http.routers.authelia.rule=Host(`auth.{{ domain }}`)
      - traefik.http.routers.authelia.entrypoints=https
      - traefik.http.routers.authelia.tls=true
      - traefik.http.routers.authelia.tls.certresolver=digitalocean
      - traefik.http.routers.authelia.middlewares=rate-limit@file,authelia-headers
      - traefik.http.middlewares.authelia-headers.headers.browserXssFilter=true
      - traefik.http.middlewares.authelia-headers.headers.customResponseHeaders.Cache-Control=no-store
      - traefik.http.middlewares.authelia-headers.headers.customResponseHeaders.Pragma=no-cache
      - traefik.http.middlewares.authelia-headers.headers.customFrameOptionsValue=SAMEORIGIN

  # monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    restart: unless-stopped
    healthcheck:
      test: wget --no-verbose --tries=1 --spider http://localhost:9090/-/healthy || exit 1
      interval: 30s
      timeout: 3s
      retries: 30
    expose:
      - 9090
    environment:
      TZ: '{{ timezone }}'
    volumes:
      - prometheus:/prometheus
      - '{{ root_path }}/prometheus:/etc/prometheus'
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=168h'
      - '--web.enable-lifecycle'
      - '--web.external-url=http://localhost:9090/'
    networks:
      - proxy
      - monitoring
    extra_hosts:
      - 'dockerhost:172.20.1.1'
    labels:
      - traefik.enable=true
      - traefik.http.routers.prometheus.rule=Host(`prometheus.{{ domain }}`)
      - traefik.http.routers.prometheus.entrypoints=https
      - traefik.http.routers.prometheus.tls=true
      - traefik.http.routers.prometheus.tls.certresolver=digitalocean
      - traefik.http.routers.prometheus.middlewares=auth@file,rate-limit@file
  alertmanager:
    image: prom/alertmanager:latest
    container_name: alertmanager
    restart: unless-stopped
    depends_on:
      - prometheus
    expose:
      - 9093
    volumes:
      - alertmanager:/alertmanager
      - '{{ root_path }}/alertmanager:/etc/alertmanager'
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
    networks:
      - monitoring
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    restart: unless-stopped
    healthcheck:
      test: wget --no-verbose --tries=1 --spider http://localhost:3000/api/health || exit 1
      interval: 30s
      timeout: 3s
      retries: 30
    depends_on:
      - prometheus
    expose:
      - 3000
    environment:
      TZ: '{{ timezone }}'
      GF_SECURITY_ADMIN_USER: '{{ network.grafana_user }}'
      GF_SECURITY_ADMIN_PASSWORD: '{{ network.grafana_password }}'
      GF_INSTALL_PLUGINS: grafana-piechart-panel
    volumes:
      - grafana:/var/lib/grafana
      - '{{ root_path }}/grafana/grafana.ini:/etc/grafana/grafana.ini'
      - '{{ root_path }}/grafana/provisioning:/etc/grafana/provisioning'
    networks:
      - proxy
      - monitoring
    labels:
      - traefik.enable=true
      - traefik.http.routers.grafana.rule=Host(`grafana.{{ domain }}`)
      - traefik.http.routers.grafana.entrypoints=https
      - traefik.http.routers.grafana.tls=true
      - traefik.http.routers.grafana.tls.certresolver=digitalocean
      - traefik.http.routers.grafana.middlewares=auth@file,rate-limit@file
  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    restart: unless-stopped
    expose:
      - 9100
    volumes:
      - /:/rootfs:ro
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc)($$|/)'
    networks:
      - monitoring
  cadvisor:
    image: budry/cadvisor-arm:latest
    container_name: cadvisor
    restart: unless-stopped
    expose:
      - 8080
    volumes:
      - /:/rootfs:ro
      - /sys:/sys:ro
      - /var/run:/var/run:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    command:
      - '--docker_only=true'
    networks:
      - monitoring
  unifi-exporter:
    image: golift/unifi-poller:latest
    container_name: unifi-exporter
    restart: unless-stopped
    depends_on:
      - unifi
    expose:
      - 9130
    volumes:
      - '{{ root_path }}/unifi-exporter/unifi-poller.conf:/config/unifi-poller.conf'
    networks:
      - monitoring
  pihole-exporter:
    image: ekofr/pihole-exporter:0.0.10
    container_name: pihole-exporter
    restart: unless-stopped
    depends_on:
      - pihole
    expose:
      - 9617
    environment:
      PIHOLE_HOSTNAME: pihole
      PIHOLE_PASSWORD: '{{ network.pi_hole_password }}'
    networks:
      - monitoring
  fritzbox-exporter:
    image: sealife/fritzbox-exporter:latest
    container_name: fritzbox-exporter
    restart: unless-stopped
    expose:
      - 8765
    environment:
      FRITZ_HOST: '{{ network.router_ip }}'
      FRITZ_USER: '{{ network.fritzbox_user }}'
      FRITZ_PASS: '{{ network.fritzbox_password }}'
    networks:
      - monitoring
  speedtest-exporter:
    image: shrunbr/speedtest-exporter-arm:latest
    container_name: speedtest-exporter
    restart: unless-stopped
    expose:
      - 9112
    networks:
      - monitoring

  # services
  homer:
    image: b4bz/homer:latest
    container_name: homer
    restart: always
    healthcheck:
      test: wget --no-verbose --tries=1 --spider http://localhost:8080 || exit 1
      interval: 30s
      timeout: 3s
      retries: 30
    expose:
      - 8080
    environment:
      TZ: '{{ timezone }}'
      UID: 1000
      GID: 1000
    volumes:
      - '{{ root_path }}/homer/assets:/www/assets'
      - '{{ root_path }}/homer/config.yml:/www/assets/config.yml'
    networks:
      - proxy
    labels:
      - traefik.enable=true
      - traefik.http.routers.homer.rule=Host(`{{ domain }}`)
      - traefik.http.routers.homer.entrypoints=https
      - traefik.http.routers.homer.tls=true
      - traefik.http.routers.homer.tls.certresolver=digitalocean
      - traefik.http.routers.homer.middlewares=rate-limit@file
  unifi:
    image: ryansch/unifi-rpi:latest
    container_name: unifi
    restart: unless-stopped
    depends_on:
      - pihole
    ports:
      - '3478:3478/udp' # stun
      - '8080:8080' # device <-> controller communication
      - '8443:8443' # controller ui
      - '8880:8880' # http portal redirect
      - '8843:8843' # https portal redirect
      - '6789:6789' # mobile speed test
      - '10001:10001/udp' # device discovery
    volumes:
      - '{{ root_path }}/unifi/config:/var/lib/unifi'
      - '{{ root_path }}/unifi/log:/usr/lib/unifi/logs'
      - '{{ root_path }}/unifi/log2:/var/log/unifi'
      - '{{ root_path }}/unifi/run:/usr/lib/unifi/run'
      - '{{ root_path }}/unifi/run2:/run/unifi'
      - '{{ root_path }}/unifi/work:/usr/lib/unifi/work'
    networks:
      - proxy
      - monitoring
    labels:
      - traefik.enable=true
      - traefik.http.routers.unifi.rule=Host(`unifi.{{ domain }}`)
      - traefik.http.routers.unifi.entrypoints=https
      - traefik.http.routers.unifi.tls=true
      - traefik.http.routers.unifi.tls.certresolver=digitalocean
      - traefik.http.routers.unifi.middlewares=auth@file,rate-limit@file
      - traefik.http.services.unifi-network.loadbalancer.server.scheme=https
      - traefik.http.services.unifi-network.loadbalancer.server.port=8443
      - traefik.http.middlewares.unifi.headers.sslredirect=true
      - traefik.http.middlewares.unifi.headers.stsSeconds=315360000
      - traefik.http.middlewares.unifi.headers.browserXSSFilter=true
      - traefik.http.middlewares.unifi.headers.contentTypeNosniff=true
      - traefik.http.middlewares.unifi.headers.forceSTSHeader=true
      - traefik.http.middlewares.unifi.headers.STSIncludeSubdomains=true
      - traefik.http.middlewares.unifi.headers.STSPreload=true
      - traefik.http.middlewares.unifi.headers.frameDeny=true
      - traefik.http.middlewares.unifi.headers.accessControlAllowCredentials=true
      - traefik.http.middlewares.unifi.headers.SSLHost=unifi.{{ domain }}
  pihole:
    image: pihole/pihole:latest
    container_name: pihole
    hostname: pihole
    restart: unless-stopped
    depends_on:
      - cloudflared
    ports:
      - '53:53'
      - '53:53/udp'
    expose:
      - 80
    environment:
      TZ: '{{ timezone }}'
      VIRTUAL_PORT: 80
      PIHOLE_DNS_: 172.20.3.2#5053
      DNS_FQDN_REQUIRED: 'true'
      WEBPASSWORD: '{{ network.pi_hole_password }}'
      REV_SERVER: 'true'
      REV_SERVER_CIDR: '{{ network.network }}'
      REV_SERVER_TARGET: '{{ network.router_ip }}'
      REV_SERVER_DOMAIN: fritz.box
      PROXY_LOCATION: pihole
      SKIPGRAVITYONBOOT: 'true'
      WEBUIBOXEDLAYOUT: traditional
      TEMPERATUREUNIT: c
    volumes:
      - '{{ root_path }}/pihole/etc-pihole/:/etc/pihole/'
      - '{{ root_path }}/pihole/etc-dnsmasq.d/:/etc/dnsmasq.d/'
    networks:
      - proxy
      - monitoring
      - dns
    dns:
      - 127.0.0.1
      - 1.1.1.1
    cap_add:
      - NET_ADMIN
    labels:
      - traefik.enable=true
      - traefik.http.routers.pihole.rule=Host(`pihole.{{ domain }}`)
      - traefik.http.routers.pihole.entrypoints=https
      - traefik.http.routers.pihole.middlewares=auth@file,rate-limit@file,pihole-addprefix
      - traefik.http.routers.pihole.tls=true
      - traefik.http.routers.pihole.tls.certresolver=digitalocean
      - traefik.http.services.pihole-network.loadbalancer.server.port=80
      - traefik.http.middlewares.pihole-addprefix.addprefix.prefix=/admin
  cloudflared:
    image: crazymax/cloudflared:latest
    container_name: cloudflared
    restart: unless-stopped
    ports:
      - '5053:5053/udp'
    expose:
      - 49312
    environment:
      TZ: '{{ timezone }}'
      TUNNEL_DNS_UPSTREAM: https://1.1.1.1/dns-query,https://1.0.0.1/dns-query
    networks:
      monitoring: {}
      dns:
        ipv4_address: 172.20.3.2
  homeassistant:
    image: homeassistant/home-assistant:stable
    container_name: homeassistant
    restart: unless-stopped
    network_mode: host
    environment:
      TZ: '{{ timezone }}'
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - '{{ root_path }}/home-assistant:/config'
    dns:
      - 127.0.0.1
    devices:
      - /dev/ttyACM0:/dev/ttyACM0
  dyndns:
    image: tunix/digitalocean-dyndns-armv7:latest
    container_name: dyndns
    restart: unless-stopped
    environment:
      TZ: '{{ timezone }}'
      DIGITALOCEAN_TOKEN: '{{ digital_ocean_token }}'
      DOMAIN: '{{ domain }}'
      NAME: vpn
    networks:
      - dns
networks:
  proxy:
    ipam:
      config:
        - subnet: 172.20.1.0/24
          gateway: 172.20.1.1
  monitoring:
    ipam:
      config:
        - subnet: 172.20.2.0/24
          gateway: 172.20.2.1
  dns:
    ipam:
      config:
        - subnet: 172.20.3.0/24
          gateway: 172.20.3.1
  docker:
    ipam:
      config:
        - subnet: 172.20.4.0/24
          gateway: 172.20.4.1
volumes:
  prometheus:
  alertmanager:
  grafana:
  portainer:
